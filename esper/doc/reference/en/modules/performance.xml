<chapter id="performance" revision="1">

    <title>Performance</title>

    <para>
        Esper has been highly optimized to handle very high throughput stream with very little latency for each events.
        It is also possible to use Esper on a soft-real-time or hard-real-time JVM to maximize predictibiliy even
        further.
    </para>

    <para>
        This section describes performance best practices and explains how to assess Esper performance by using our
        provided performance kit. It also sums up some of the Esper performance results.
    </para>

    <sect1 id="performance-intro" revision="1">
        <title>Best practices</title>

        <para>
            When planning for performance measurement you need to take account for the following:
        </para>

        <orderedlist>
            <listitem>
                <para>
                    Turn off Esper logging (keep only INFO or more critical messagess). Since Esper 1.10, even if you
                    don't have
                    a log4j configuration file in place, Esper will make sure to minimmize logging overhead.
                </para>
            </listitem>
            <listitem>
                <para>
                    Understand how to tune a JVM. Esper runs on a JVM and you need to be familiar with JVM tuning.
                    Key parameters to consider include min and max heap and nursery.
                    Statements with time based or length based views will consume memory as their size / length is big.
                    For time based views
                    you need to be aware that the memory consume will thus depend on the actual event stream input
                    throughput.
                    Event patterns also consume memory when using the
                    <literal>every</literal>
                    keyword- wich again will depend on the actual event streams input throughput.
                </para>
            </listitem>
            <listitem>
                <para>
                    If you compare Esper performance to another solution, you need to ensure that your statements have
                    strict
                    equivalent semantics despite some vague similarities.
                    For example some vendor solution mandates the use of bounded stream
                    <programlisting><![CDATA[
// other (name ommitted) vendor statement:
select * from (select * from Market where ticker = 'GOOG') retain 1 event
// Esper statement that DOES ***NOT*** HAVE the same semantics:
select * from Market(ticker='$')
// Esper statement that DOES HAVE the same semantics:
select * from Market(ticker='$').win:length(1)
                    ]]></programlisting>
                </para>
            </listitem>
            <listitem>
                <para>
                    Esper stream-level filtering is more optimized than select-level where clause filtering. In simple statements
                    they may have similar semantics, so you should make sure you are performance testing well written statements.
                    Consider the example below:
                    <programlisting><![CDATA[
// stream-level filtering (more optimized):
select avg(price) from Market(ticker = 'GOOG').win:length(100)
// select-level where clause filtering (less efficient):
select avg(price) from Market.win:length(100) where ticker = 'GOOG'
                    ]]></programlisting>
                    Note that those two statements do not have the same semantics because the second statement considers
                    average of the GOOG tick for any sliding window of 100 ticks.
                </para>
            </listitem>
        </orderedlist>
    </sect1>

    <sect1 id="performance-results" revision="1">
        <title>Performance results</title>

        <para>
            Results in this section are based on runs performed with the performance kit. It provides key figures to
            assess
            Esper performance but do not represent best ever obtained results. They may help you better compare
            Esper to other solutions (for latency, throughput and CPU utilization) and also assess your target hardware and JVMs.
        </para>

        <para>
            For a complete understanding of those results, consult the next section.
        </para>

        <para>
            The benchmark application is basically an Esper event server build with Esper that listen to remote clients
            over TCP.
            Remote clients send MarketData(ticker, price, volume) streams to the event server.
            The Esper event server is started with 1000 statetements of one single kind (unless otherwised written),
            with one statement per ticker symbol.
            The statement prototype is provided along the results with a '$' instead of the ticker symbol.
            The Esper event server is entirely multithreaded and can leverage the full power of 32bit or 64bit
            underlying hardware
            multi-processor multi-core architecture.
        </para>

        <sect2 id="config" revision="1">
            <title>Configuration</title>

            <para>
                The results described in the next section where obtained with:
            </para>
            <table frame="topbot">
                <title>Benchmark configuration</title>
                <tgroup cols="2">
                    <thead>
                        <row>
                            <entry>Item</entry>
                            <entry>Specification</entry>
                        </row>
                    </thead>
                    <tbody>
                        <row>
                            <entry>Operating System for Esper event server and client</entry>
                            <entry>Red Hat 64bit: Red Hat Enterprise Linux AS release 4 (Nahant Update 4) Linux version
                                2.6.9-42.ELsmp (bhcompile@ls20-bc1-13.build.redhat.com) (gcc version 3.4.6 20060404 (Red
                                Hat 3.4.6-2)) #1 SMP Wed Jul 12 23:32:02 EDT 2006 (x86_64)
                            </entry>
                        </row>
                        <row>
                            <entry>Hardware for Esper event server</entry>
                            <entry>2 x Intel Xeon 5130 2GHz (4 cores total), 16GB RAM</entry>
                        </row>
                        <row>
                            <entry>Hardware for client (all clients on same box)</entry>
                            <entry>2 x Intel Xeon 5130 2GHz (4 cores total), 4GB RAM</entry>
                        </row>
                        <row>
                            <entry>Network</entry>
                            <entry>100 Mbit</entry>
                        </row>
                        <row>
                            <entry>JVM version (server and client)</entry>
                            <entry>BEA JRockit(R) R27.3 linux 32bit</entry>
                        </row>
                        <row>
                            <entry>JVM paremeters (server) (basically 2GB heap, generational garbage collector)</entry>
                            <entry>-Xms2g -Xmx2g -Xns128m -Xgc:gencon</entry>
                        </row>
                    </tbody>
                </tgroup>
            </table>
        </sect2>

        <sect2 id="results" revision="1">
            <title>Results</title>

            <para>
                The results presented here are max throughput as handled by the Esper event server expressed
                in number of event per second (evt/s) on the input streams. In some case we also include
                details on the intra Esper engine latency.
            </para>

            <para>
                For all results presented here, a listener instance
                <literal>net.esper.client.UpdateListener</literal>
                is registered with the statement(s) to listen for
                the Esper output events, but its body is a no-op.
            </para>

            <para>
                A first run was done in simulated mode where the server itself generates events. This helps determine
                what is the maximal throughput that can ever be achieved with the given hardware/OS/JVM configuration
                (client will add network
                latency). In such a case the server has no statement registered but still invokes
                <literal>esperRuntime.sendEvent(event)</literal>
                .
            </para>

            <table frame="topbot">
                <title>no Esper statement, simulation</title>
                <tgroup cols="2">
                    <colspec colwidth="1*"/>
                    <colspec colwidth="3*"/>
                    <thead>
                        <row>
                            <entry>Item</entry>
                            <entry>Result</entry>
                        </row>
                    </thead>
                    <tbody>
                        <row>
                            <entry>Throughput</entry>
                            <entry>993 500 evt/s</entry>
                        </row>
                        <row>
                            <entry>Latency</entry>
                            <entry>99.97% below 10us
                                <synopsis><![CDATA[
---Stats - engine (unit: ns)
  Avg: 3004 #9943509
        0 <    5000:  99.76%  99.76% #9919566
     5000 <   10000:   0.21%  99.97% #21358
    10000 <   15000:   0.00%  99.98% #330
    15000 <   20000:   0.00%  99.98% #70
    20000 <   25000:   0.00%  99.98% #54
    25000 <   50000:   0.00%  99.98% #111
    50000 <  100000:   0.00%  99.98% #33
   100000 <  500000:   0.00%  99.98% #213
   500000 < 1000000:   0.00%  99.98% #16
  1000000 < 2500000:   0.00%  99.98% #124
  2500000 < 5000000:   0.01%  99.99% #1080
  5000000 <    more:   0.01% 100.00% #554
                        ]]></synopsis>
                            </entry>
                        </row>
                        <row>
                            <entry>Notes</entry>
                            <entry>Simulated with -rate=14x100000</entry>
                        </row>
                    </tbody>
                </tgroup>
            </table>


            <para>
                A second run was done in client/server mode where the several clients generate events and send them over
                TCP.
                The server has no statement registered but still invokes
                <literal>esperRuntime.sendEvent(event)</literal>
                . This
                helps determine how much the network and server middleware will account when comparing to the previous
                simulated run.
            </para>

            <table frame="topbot">
                <title>no Esper statement, with 7 clients (50 000 evt/s sent by each client)</title>
                <tgroup cols="2">
                    <colspec colwidth="1*"/>
                    <colspec colwidth="3*"/>
                    <thead>
                        <row>
                            <entry>Item</entry>
                            <entry>Result</entry>
                        </row>
                    </thead>
                    <tbody>
                        <row>
                            <entry>Throughput</entry>
                            <entry>274 971 evt/s</entry>
                        </row>
                        <row>
                            <entry>Latency (Esper)</entry>
                            <entry>99.52% below 10us
                                <synopsis><![CDATA[
---Stats - engine (unit: ns)
  Avg: 1901 #2737661
        0 <    5000:  99.03%  99.03% #2711113
     5000 <   10000:   0.49%  99.52% #13518
    10000 <   15000:   0.31%  99.84% #8531
    15000 <   20000:   0.13%  99.97% #3684
    20000 <   25000:   0.02%  99.99% #444
    25000 <   50000:   0.01%  99.99% #157
    50000 <  100000:   0.00%  99.99% #36
   100000 <  500000:   0.00% 100.00% #89
   500000 < 1000000:   0.00% 100.00% #24
  1000000 < 2500000:   0.00% 100.00% #53
  2500000 < 5000000:   0.00% 100.00% #9
  5000000 <    more:   0.00% 100.00% #3
                        ]]></synopsis>
                            </entry>
                        </row>
                        <row>
                            <entry>Latency (end to end from client to server including Esper processing)</entry>
                            <entry>99.79% below 50ms
                                <synopsis><![CDATA[
---Stats - endToEnd (unit: ms)
  Avg: 21 #2737983
        0 <       1:   0.00%   0.00% #0
        1 <       5:   0.03%   0.03% #930
        5 <      10:   0.82%   0.85% #22478
       10 <      50:  98.94%  99.79% #2708853
       50 <     100:   0.21% 100.00% #5722
      100 <     250:   0.00% 100.00% #0
      250 <     500:   0.00% 100.00% #0
      500 <    1000:   0.00% 100.00% #0
     1000 <    more:   0.00% 100.00% #0
                        ]]></synopsis>
                            </entry>
                        </row>
                        <row>
                            <entry>Notes</entry>
                            <entry>A traffic of 91 Mbit/s was observed on the network - the results are thus limited by
                                the network capacity. Total CPU load was at 65%.
                            </entry>
                        </row>
                    </tbody>
                </tgroup>
            </table>

            <para>
                The next run is Straight Through Processing, which shows how efficiently Esper performs stream
                filtering.
            </para>

            <table frame="topbot">
                <title>select * from Market(ticker='$') output last every 30 seconds (x 1000 statements)</title>
                <tgroup cols="2">
                    <colspec colwidth="1*"/>
                    <colspec colwidth="3*"/>
                    <thead>
                        <row>
                            <entry>Item</entry>
                            <entry>Result</entry>
                        </row>
                    </thead>
                    <tbody>
                        <row>
                            <entry>Throughput</entry>
                            <entry>xxx evt/s</entry>
                        </row>
                        <row>
                            <entry>Latency (Esper)</entry>
                            <entry>xx% below xxus
                                <synopsis><![CDATA[
                        ]]></synopsis>
                            </entry>
                        </row>
                        <row>
                            <entry>Latency (end to end from client to server including Esper processing)</entry>
                            <entry>xx% below xxms
                                <synopsis><![CDATA[
                        ]]></synopsis>
                            </entry>
                        </row>
                        <row>
                            <entry>Notes</entry>
                            <entry>A traffic of 91 Mbit/s was observed on the network - the results are thus limited by
                                the network capacity. Total CPU load was at 65%.
                            </entry>
                        </row>
                    </tbody>
                </tgroup>
            </table>

        </sect2>

    </sect1>


    <sect1 id="performance-kit" revision="1">
        <title>Using the performance kit</title>

        <sect2 id="how-to-kit" revision="1">
            <title>How to use the performance kit</title>

            <para>
                The Esper event server, client and statement protypes are provided in the source repository
                <literal>esper/trunk/examples/benchmark/</literal>
                . Refer to http://xircles.codehaus.org/projects/esper/repo
                for source access.
            </para>

            <para>
                A built is provided for convenience (without sources) at xxx.
                It contains Ant script to start client, server in simulation mode and server. For real measurement we
                advise
                to start from a shell script (because Ant is pipelining stdout/stderr when you invoke a JVM from Ant -
                which
                is costly). Sample scripts are provided.
            </para>

            <para>
                If you use the kit you should:
            </para>

            <orderedlist>
                <listitem>
                    <para>
                        Choose the statement you want to benchmark, add it to
                        <literal>etc/statements.properties</literal>
                        under
                        your own KEY and use the
                        <literal>-mode KEY</literal>
                        when you start the Esper event server.
                    </para>
                </listitem>
                <listitem>
                    <para>
                        Prepare your runServer.sh/runServer.cmd and runClient.sh/runclient.cmd scripts. You'll need to
                        drop required
                        jar libraries in
                        <literal>lib/</literal>
                        , configure the classpath in those script to include
                        <literal>build</literal>
                        and
                        <literal>etc</literal>
                        . The required libraries are Esper (any compatible version, we have tested started with Esper
                        1.7.0)
                        and its dependencies as in the sample below (with Esper 1.10) :
                        <programlisting><![CDATA[
# classpath on Unix/Linux (on one single line)
etc:build:lib/esper-1.10.0.jar:lib/commons-logging-1.0.3.jar:lib/cglib-full-2.0.2.jar
   :lib/antlr-2.7.5.jar:lib/log4j-1.2.8.jar
@rem  classpath on Windows (on one single line)
etc;build;lib\esper-1.10.0.jar;lib\commons-logging-1.0.3.jar;lib\cglib-full-2.0.2.jar
   ;lib\antlr-2.7.5.jar;lib\log4j-1.2.8.jar
              ]]></programlisting>
                        Note that <literal>./etc</literal> and <literal>./build</literal> have to be in the classpath.
                        At that stage you should also start to set min and max JVM heap. A good start is 1GB as in
                        <literal>-Xms1g -Xmx1g</literal>
                    </para>
                </listitem>
                <listitem>
                    <para>
                        Write the statement you want to benchmark given that client will send a stream MarketData(String
                        ticker, int volume, double price), add it to
                        <literal>etc/statements.properties</literal>
                        under
                        your own KEY and use the
                        <literal>-mode KEY</literal>
                        when you start the Esper event server.
                    </para>
                </listitem>
                <listitem>
                    <para>
                        Write the statement you want to benchmark given that client will send a stream MarketData(String
                        ticker, int volume, double price), add it to
                        <literal>etc/statements.properties</literal>
                        under
                        your own KEY and use the
                        <literal>-mode KEY</literal>
                        when you start the Esper event server.
                    </para>
                </listitem>
                <listitem>
                    <para>
                        Establish a performance baseline in simulation mode (without clients). Use the
                        <literal>-rate 1x5000</literal>
                        option
                        to simulate one client (one thread) sending 5000 evt/s. You can ramp up both the number of client simulated
                        thread and their emission rate to maximize CPU
                        utlization.
                        The right number should mimic the client emission rate you will use in the client/server benchmark
                        and should thus be
                        consistent with what your client machine and network will be able to send.
                    </para>
                </listitem>
                <listitem>
                    <para>
                        Do performance runs with client/server mode. Start the server without the
                        <literal>-rate NxM</literal>
                        option.
                        Start the server with
                        <literal>-help</literal>
                        to display the possible options (listen port, statistics, fan out options etc).
                        On the remote machine, start one or more client. Use
                        <literal>-help</literal>
                        to display the possible options (remote port, host,
                        emission rate). The client will output the actual number of event it is sending to the server.
                        If the server gets overloaded (or if you turned on
                        <literal>-queue</literal>
                        options on the server) the client will likely
                        not be able to reach its target rate.
                    </para>
                </listitem>
            </orderedlist>
        </sect2>

        <sect2 id="how-we-kit" revision="1">
            <title>How we use the performance kit</title>

            <para>
                We use the performance kit to track performance progress accross Esper versions, as well as to implement
                optimizations. You can track our work on the wiki at http://docs.codehaus.org/display/ESPER/Home
            </para>

        </sect2>
    </sect1>
</chapter>
